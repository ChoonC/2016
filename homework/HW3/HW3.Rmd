---
title: 'Homework 3: Is Donald Trump going to win the republican nomination?'
output: html_document
---

**This homework is due Tuesday March 8, 2016 at 8PM EST. When complete, submit your code in an R Markdown file and the knitted HTML via GitHub.**

# Motivation

In 2012 Nate Silver, and other data scientists, [predicted the outcome of each state correctly](http://mashable.com/2012/11/07/nate-silver-wins/#2WkAUaXCVaqw). 
They did this by aggregating data from many polls to create more precise
estimates than what one single poll can provide.

In this homework, we will try to predict the results of the democratic 
and republican primaries by studying the performance of polls in 
elections that already occurred and then aggregating results.


# Problem 1 

The first step in our analysis will be to wrangle the data in a way 
that will simplify the analysis. Ultimately, we want a table of results 
with each poll represented by a row and including results for each 
candidate as well as information about the poll such as name and date.

#  Problem 1A

Install and load the `pollstR` package. This package provides functions 
to access data in the Huffington Post's database. Read the help file 
for the `pollstr_polls()` function and write a function that reads 
**all** the polls related to the republican primaries. Name the object 
`race2016`. Hint: Visit 
[this webpage](http://elections.huffingtonpost.com/pollster/api) 
to select the right `topic` and make sure to change the `max_pages` argument. 


```{r, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE}

library(pollstR)
race2016 <- pollstr_polls(topic = '2016-president-gop-primary', max_pages = Inf)

```
# Problem 1B

Examine and familiarize yourself with the `race2016` object. Note 
that the `questions` component has a table with election results. 
Look at the `topic` component of the `questions` component. Create a new 
table with only the results from the `2016-president-gop-primary` 
and only state (or territory) polls, no national polls. Hint: create 
a new object called `results` with the table of results and 
use `dplyr`. How many rows are we left with?

```{r}
library(dplyr)
results <- tbl_df(race2016$questions %>% filter(topic=="2016-president-gop-primary" & state != "US")) 
results %>% nrow()

```


## Problem 1C

In Problem 1B, we created a table called `results` with over 4000 rows. 
Does this mean that we have data for 4000 polls? How many polls 
did we actually have? 
Hint: look at the `id` column and use the `group_by` command.

```{r}
table(results$id) %>% nrow()
```


## Problem 1D

Look at the first row of your `results` table. 
What date was this poll conducted? 
Hint: Use the `polls` component of the `race2016` object to find the date.

```{r}
id1 <- results[1,]$id
race2016$polls %>% filter(id == id1) %>% select(start_date, end_date)

```

## Problem 1E

Now examine the candidates in the "choices" column included in `results` table. 
Hint: use the `table()` function. Note that there are several choices that
not going to be informative. For example, we have candidates that have
dropped out. We also have entries such as `No one`, `No One` and 
`No Preference`. Filter the `results` table to include only Rubio and Trump. 

```{r}
library(tidyr)
results <- filter(results, choice %in% c("Rubio","Trump"))  
results %>% nrow()

```

## Problem 1F

In our `results` table, we have one row for each candidate in each poll. 
Transform the `results` table to have one row for each poll and columns 
for each Rubio and Trump. Next, create a column called `diff` with the 
difference between Trump and Rubio. Hint: Remove the `first_name` and 
`last_name` columns then use the `tidyr` function `spread()`.


```{r}
#remove duplicated polls 
results <- unique(results)  
results <- results %>% select(-c(first_name,last_name)) %>% spread(key=choice, value=value) %>% mutate(Trump=Trump/100, Rubio=Rubio/100, diff=Trump-Rubio) %>% filter(!is.na(diff))
results %>% nrow()

```

## Problem 1G 

For each poll in the `results` table, we want to know the start date and the 
end date of the poll along with the pollster name and the type of poll it was.
Hint: This information is in the `polls` component of `race2016`. 
You can select the relevant columns then use the `id` column to join the
tables. One of the `join` functions in `tidyr` will do the trick.

```{r}
polls <- race2016$polls %>%  select(id, pollster, start_date, end_date, method)
#remove duplicates
polls <- unique(polls)  
results <- inner_join(results, polls, by = "id")
results %>% nrow()
```


## Problem 1H

Study the type of values in the `pollster` column. Notice that you 
have many different values but that certain names commonly appear 
in these values. For example, consider the name "NBC" in the `pollster`
column. NBC here is the Survey House. Use a join function again to add the survey
house to the `results` table. Rename the column `house`. 
Hint: `race2016$survey_house` has the information you need.

```{r}
house <- race2016$survey_houses %>%  select(id, name) %>% rename(house = name)
#remove duplicates
house <- unique(house) 
results <- inner_join(results, house, by = "id")
results %>% nrow()
```
*Note to TA: As there are can be multiple survey houses for a poll, the join resulted in duplication of some of the polls. This would obviously impact Problem 2, however as we have asked to do this step I am ignoring the fact it resulted in duplicates.* 

=======
# Problem 2

We now have a table with all the information we need. We will now use 
the results from Iowa, New Hampshire, Nevada and South Carolina 
to determine how to create a prediction for upcoming primaries.

## Problem 2A 

Use an internet search to determine the results for the Iowa, 
New Hampshire, Nevada and South Carolina primaries for the top two
candidates. Create a table called `actual` with this information. 
Also, create a column with the actual election difference.
Use a join function to add this information to our `results` table. 


```{r}
actual <- data.frame(c("IA", "NH", "NV", "SC"), c(24.3, 35.3, 45.9, 32.5), c(23.1, 10.6, 23.9, 22.5), stringsAsFactors = FALSE)
names(actual) <- c("state", "act_Trump", "act_Rubio")
actual <- mutate(actual, act_Trump = act_Trump/100, act_Rubio = act_Rubio/100, act_diff=act_Trump-act_Rubio)
result_actual <- inner_join(results, actual, by="state")

```

## Problem 2B 

Create boxplots of the poll results for Trump in Iowa stratified by 
the pollster survey house for polls having more than 4 total results. 
Add a horizontal line with the actual results. 
Hint: Use the `group_by`, `mutate`, `filter` and `ungroup` functions in 
`dplyr` for the filtering step.

```{r}
library(ggplot2)
IA_result <- result_actual %>% filter(state=="IA") %>% group_by(house) %>% mutate(num_polls = n()) %>% filter(num_polls > 4) %>% ungroup 
IA_result %>% ggplot(aes(house, Trump, col=house)) + geom_boxplot() + geom_hline(aes(yintercept=act_Trump))

```

## Problem 2C

Using the poll results for Trump in Iowa,
compute the standard deviation for the results from each pollster house 
for polls having more than 4 total results. 
Then, study the typical standard deviation sizes used in 
these polls. Create a new table with two columns: the observed
standard deviation and the standard deviations that theory predicts. 
For the prediction you have several observations. Pick the smallest 
one. Which is larger, the observed or the theoretical?

```{r}
obs_SD <- IA_result %>% group_by(house) %>% summarize(obs_SD = sd(Trump))
theory_SD <- IA_result %>% group_by(house) %>% summarize(N=min(observations)) %>% mutate(theory_SD=sqrt(0.5*0.5/N)) %>% select(-N)
inner_join(obs_SD, theory_SD, by="house")

```
The observed standard deviation is larger.

## Problem 2D

Now using the data from Problem 2C, plot the individual values 
against the time the poll was taken (use the `end_date`). 
Repeat this for each of the four states. Use color to denote pollster house. 
Using this plot, explain why the theory does not match the observed results?

```{r}
plot_Poll <- function(s){
    result_actual %>% filter(state==s) %>% group_by(house) %>% filter(n()>4) %>% ggplot(aes(x=end_date, y=Trump, group=house)) + geom_point(aes(color=house, shape=house), size=4) +  scale_shape_manual(values=c(12:21)) + guides(colour = guide_legend(override.aes = list(size=5))) +   
 ylab("Proportion of votes for Trump") + labs(title=paste("State:", s))
  
}
plot_Poll(s="IA")
plot_Poll(s="NV")
plot_Poll(s="NH")
plot_Poll(s="SC")

```
The theory doesn't match the observed results because the proportion voting for Trump changed over time. Hence there is variability in the observed results compared to be a assumption of a fixed proportion in the theory.
Some of the polls were taken more than 6 months before the election and the opinion of people have changed over time, i.e. there is a time effect which we need to model.

## Problem 2E 

Consider the Trump - Rubio difference. For each poll in IA, NH, SC and NV, 
compute the error between the prediction and actual election results. 
Use exploratory data analysis to get an idea of how time and pollster 
impacts accuracy.

```{r}
library(lubridate)
result_actual <-  mutate(result_actual, diff_pred = diff-act_diff)

# Calulate number of days between the poll and the results
results_date <- data.frame(c("IA", "NH", "NV", "SC"), c(ymd("2016-02-01"),ymd("2016-02-09"),ymd("2016-02-23"),ymd("2016-02-20")), stringsAsFactors = FALSE)
names(results_date) <- c("state", "results_date")
result_actual <- inner_join(result_actual, results_date, by="state") %>% mutate(day=as.numeric(ymd(start_date) - results_date))

plot_Diff <- function(s){
  result_actual %>% filter(state==s) %>% group_by(pollster) %>% filter(n()>4) %>%     ggplot(aes(x=day, y=diff_pred)) + geom_line(aes(color=pollster)) +                 ylab("Difference between prediction and actual") + geom_hline(aes(yintercept=0)) +  labs(title=paste("Trump and Rubio difference between prediction and actual results for", s)) 
}

plot_Diff(s="IA")
plot_Diff(s="NV")
plot_Diff(s="NH")
plot_Diff(s="SC")

```

# Problem 2F

For polls from IA, NH, and SC, aggregate all polls from within 1 week of the 
election (use the `start_date` to determine cutoff) to provide a 
95% confidence interval for the difference between Trump and Rubio. 
Compare the following two approaches: 
(1) the method that assumes that all variance comes from sampling error 
and (2) the approach that estimates variance empirically. 

```{r}
for(s in c("IA","NH","SC")){
t <- result_actual %>% filter(state==s & day >= -7) %>%  summarize(n=n(), avg=mean(diff), sd=sd(diff), avgObs = mean(observations)) 
#1. Using t-distribution to small number of polls
cat("95% CI for", s, "(", t$avg + c(-1,1)*qt(0.975, df=t$n-1)*t$sd/sqrt(t$n),")  using t-distribution", "\n")

#2. Estimate variance empiritically
cat("95% CI for", s, "(", t$avg + c(-1,1)*qt(0.975, df=t$n-1) * 2 * sqrt(t$avg*(1-t$avg)/t$avgObs)/sqrt(t$n), ") using theory of polls", "\n")
}

```

# Problem 3

Before seeing any polls my _prior belief_ is that Rubio will beat 
Trump in Florida. If I were to quantify this belief I would say that 
the distribution of the `Trump` - `Rubio` was normal with mean 
$\mu=-20$ percent and standard deviation $\tau=10$. 
Let's call the difference $\theta$. Then 

$$
\theta \sim N( \mu, \tau)
$$

# Problem 3A

Under my prior belief, what is the chance that Trump would beat Rubio in Florida.

```{r}
cat("Probability of Trump beating Rubio in Florida =", 1- pnorm(20/10))

```

# Problem 3B

Consider the latest 25 Florida polls. Assume the poll results for the 
difference are normal distributed with mean $\theta$ and standard 
deviation $\sigma$. Provide an estimate for $\theta$ and an estimate 
of the standard deviation $\sigma$.

```{r}
poll_FL <- results %>% filter(state=="FL") %>% summarize(n=n(), theta=mean(diff), sigma=sd(diff)) 
poll_FL

```

$$ \hat{\theta} \sim N( \theta, \sigma/ \sqrt{25})$$

Now use the Central Limit Theorem to construct a confidence interval. 

```{r}
poll_FL$theta + c(-1,1)*qnorm(0.975)*poll_FL$sigma/sqrt(poll_FL$n)

```

## Problem 3C

Combine these two results to provide the mean and standard deviation of 
a posterior distribution for $\theta$. 

```{r}
mu <- -20
tau <- 10
theta <- poll_FL$theta
sigma <- poll_FL$sigma
mean_pos <- mu + (1 - (sigma^2/(sigma^2 + tau^2)))*(theta - mu)
var_pos <- 1/(1/tau^2 + 1/sigma^2)
cat("The posterior distribution has mean", mean_pos, "and standard deviation", sqrt(var_pos))
```

## Problem 3D

Use the result form Problem 3C to provide your estimate of 
Trump beating Rubio in Florida.

```{r}
cat("Probability of Trump beating Rubio in Florida  =" ,1-pnorm(mean_pos/sqrt(var_pos)))

```

# Problem 4

Use the poll data as well as the results from Super Tuesday (March 1st) and other election results that happen before the deadline to make predictions for each remaining primary. Then use these results to estimate the probability of Trump winning the republican nomination. Justify your answer with figures, statistical arguments, and Monte Carlo simulations.

It will help to learn about how delegates are assigned. Here is [the manual].(http://www.scribd.com/doc/294928557/2016-Presidential-Nominating-Process-Book-version-2-0-Dec-2015-pdf)




